{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18c43faa",
   "metadata": {},
   "source": [
    "[Links to Train notebook script](https://www.kaggle.com/code/ethanyee2706/project-01-anains)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c79338e",
   "metadata": {},
   "source": [
    "# **I &nbsp;&nbsp;&nbsp; Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b705f03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manipulate models\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from peft import LoraConfig, get_peft_model, TaskType, PeftModel\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "import numpy as np # Manipulate matrices\n",
    "import pandas as pd # Manipulate and analyze data\n",
    "\n",
    "# Visual plot\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report# Visual models evaluation\n",
    "\n",
    "from data_preprocessor import DataPreprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24fde3b",
   "metadata": {},
   "source": [
    "# **II &nbsp;&nbsp;&nbsp; Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a6dd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"../../data/input/cleaned/train/train.csv\"\n",
    "test_path = \"../../data/input/cleaned/test/test.csv\"\n",
    "val_path = \"../../data/input/cleaned/val/val.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb9aeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)\n",
    "val_df = pd.read_csv(val_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49397374",
   "metadata": {},
   "source": [
    "## **1 &nbsp;&nbsp;&nbsp; Encode Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce767d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"vinai/phobert-base\",\n",
    "    use_fast=True,\n",
    "    trust_remote_code=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f0ae68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhoBERTSADataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_length=256):\n",
    "        self.texts = df.Text.astype(str).to_list()\n",
    "        self.labels = df.Label.astype(int).to_list()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = self.texts[index]\n",
    "        label = self.labels[index]\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
    "            \"token_type_ids\": encoding[\"token_type_ids\"].squeeze(0),\n",
    "            \"label\": torch.tensor([label], dtype=torch.long)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5fd662",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = PhoBERTSADataset(train_df, tokenizer, 256)\n",
    "test_ds = PhoBERTSADataset(test_df, tokenizer, 256)\n",
    "val_ds = PhoBERTSADataset(val_df, tokenizer, 256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b030a465",
   "metadata": {},
   "source": [
    "# **III &nbsp;&nbsp;&nbsp; Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb3ad6c",
   "metadata": {},
   "source": [
    "## **1 &nbsp;&nbsp;&nbsp; Load Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcad57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"vinai/phobert-base\",\n",
    "    num_labels=3,\n",
    "    trust_remote_code=False,\n",
    ")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16726fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_CLS,  \n",
    "    r=16,                        \n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0,\n",
    "    target_modules=[\n",
    "        \"query\",\n",
    "        \"key\",\n",
    "        \"value\",\n",
    "        \"dense\"\n",
    "    ], \n",
    "    bias=\"none\",\n",
    ")\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a22a68c",
   "metadata": {},
   "source": [
    "## **2 &nbsp;&nbsp;&nbsp; Train Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51507286",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir = \"fine-tuned_PhoBERT\",\n",
    "    \n",
    "    eval_strategy = \"epoch\",\n",
    "    per_device_train_batch_size = 32,\n",
    "    per_device_eval_batch_size = 32,\n",
    "    gradient_accumulation_steps = 4,\n",
    "    \n",
    "    learning_rate = 2e-4,\n",
    "    weight_decay = 0.01,\n",
    "    \n",
    "    num_train_epochs = 10,\n",
    "    warmup_ratio = 0.05,\n",
    "    lr_scheduler_type = \"linear\",\n",
    "    logging_steps = 1,\n",
    "    \n",
    "    seed = 3407,\n",
    "    dataloader_num_workers=2,\n",
    "    \n",
    "    remove_unused_columns = False,\n",
    "    report_to = \"none\",  \n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args = training_args,\n",
    "    train_dataset = train_ds,\n",
    "    eval_dataset = val_ds,\n",
    "    tokenizer = tokenizer\n",
    ")\n",
    "\n",
    "trainer_stats = trainer.train()\n",
    "logs = trainer.state.log_history\n",
    "\n",
    "visual_loss = [ log[\"loss\"] for log in logs if \"loss\" in log and \"eval_loss\" not in log ]\n",
    "val_loss = [ log[\"eval_loss\"] for log in logs if \"eval_loss\" in log ]\n",
    "train_loss = [loss for i, loss in enumerate(visual_loss) if (i % 150 == 0) or (i == len(visual_loss) - 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe2f5a2",
   "metadata": {},
   "source": [
    "## **3&nbsp;&nbsp;&nbsp; Evaluate Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f81e353",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = trainer.predict(test_ds)\n",
    "y_pred = np.argmax(predictions.predictions, axis=1)\n",
    "y_true = predictions.label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694bb93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true, y_pred)\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "print(classification_report(y_true, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fc5356",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iters = 1500\n",
    "eval_iters = 150\n",
    "num_classes = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68554a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=True, linewidths=0.5)\n",
    "plt.xlabel(\"Predicted\", fontsize=12)\n",
    "plt.ylabel(\"True\", fontsize=12)\n",
    "plt.xticks(ticks=np.arange(num_classes)+0.5, labels=range(num_classes))\n",
    "plt.yticks(ticks=np.arange(num_classes)+0.5, labels=range(num_classes), rotation=0)\n",
    "\n",
    "plt.title(\"Confusion Matrix\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"lstmcm.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0885b292",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = list(range(149, train_iters, eval_iters))\n",
    "plt.figure(figsize=(8, 4))\n",
    "\n",
    "plt.plot(steps, train_loss, linewidth=1.5, label=\"Train Loss\")\n",
    "plt.plot(steps, val_loss, linewidth=1.5, label=\"Validation Loss\")\n",
    "\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"fine-tuned_PhoBERT/berttrainvalloss.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36ed91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = list(range(0, train_iters))\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "plt.plot(steps, visual_loss, linewidth=1, label=\"Train Loss\",)\n",
    "\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"fine-tuned_PhoBERT/berttrainloss.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf08d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"Sản phẩm rất tệ\"\n",
    "\n",
    "preprocessor = DataPreprocessor()\n",
    "preprocessed_text = preprocessor.preprocess(input_text)\n",
    "encoded_text = tokenizer(\n",
    "    preprocessed_text,\n",
    "    add_special_tokens=True,\n",
    "    truncation=True,\n",
    "    padding=\"max_length\",\n",
    "    max_length=256,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "def predict_sentiment(text):\n",
    "    model.eval()\n",
    "    text = text.to(\"cpu\")\n",
    "    logits = model(**text).logits\n",
    "    pred = torch.argmax(logits)\n",
    "    return pred\n",
    "\n",
    "result = predict_sentiment(encoded_text)\n",
    "print(result.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2cd48c",
   "metadata": {},
   "source": [
    "## **4 &nbsp;&nbsp;&nbsp; Save Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c469f0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"fine-tuned_PhoBERT\")\n",
    "tokenizer.save_pretrained(\"fine-tuned_PhoBERT\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.14.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
